{"code": "## Problem\nThank you for taking the time out of your day to tackle this problems set with us! We expect the solution to be\nwritten in **Python**, if you choose to use libraries (i.e **pandas**) to help you accomplish the task at hand,\nwe ask that you leave plenty room in your work to showcase your **algorithms**, and **design** skillsets.\nIf you are unsure about how much usage is too much, we would err on the side of minimizing 3rd party library\nfoot print, this helps ensure we have as much material as possible to evaluate your abilities as an engineer.\n\nWe expect each candidate to spend no more than 2 hours on the solution (we'll take your\nword for it \ud83d\ude07). As there are multiple parts to the question, do not feel the need to complete it\nall, instead please feel free to stop once you've crossed the two hour mark. If you were in\nthe midst of a question, feel free to leave some pseudocode for how you would've completed it.\n", "explanation": "This block is a set of guidelines for a coding exercise in Python. It emphasizes showcasing personal algorithms and design skills, minimizing third-party library usage, and limits completion time to 2 hours.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Backend/README.md", "chunk_number": 1, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "# Backend README\n\n## Overview\n\nThis coding exercise is designed to evaluate your Python programming skills, focusing on algorithm design and implementation. You have 2 hours to complete the tasks.\n\n## Tasks\n\n### Part 1\n\nWrite a function to find the `station_id` and `date` pair with the lowest recorded temperature.\n\n### Part 2\n\nWrite a function to find the `station_id` with the most temperature fluctuation across all reported dates.\n\n### Bonus Task\n\nDevelop a function that identifies the `station_id` with the most significant temperature fluctuation between a given date range.\n\n## Evaluation Criteria\n\n* Correctness\n* Readability\n* Coherent design\n* Test coverage\n\n## Guidelines\n\n* Minimize third-party library usage\n* Showcase your personal algorithms and design skills"}
{"code": "You'll find the dataset for the questions in `data.csv` after unzipping `data.csv.zip`. The dataset\nrepresents temperatures reported by specific weather stations (`station_id`) at a particular point\nin time (`date`). The first 4 digits of the `date` value represents the year that the temperature was\ncollected, the second 3 digit portion appearing after the `.` represents a unique point during the\nyear such that no two days within the year has the same 3 digit representation.\n\n\n**Part 1**:\n\nCreate a function that when called returns the `station_id`, and `date` pair that reported the\nlowest temperature. If a tie occurs simply return one pair at random.\n\n**Part 2**:\n\nCreate a function that returns the `station_id` that experienced the most amount of temperature\nfluctuation across all dates that it reported temperatures for. For example with the following dataset:\n\n    station_id,     date, temperature_c\n             1, 2000.001,             5\n             1, 2000.123,             0", "explanation": "**Summary:**\n\nThe given text describes a dataset of temperatures reported by weather stations and outlines two tasks:\n\n1. **Part 1:** Create a function to find the `station_id` and `date` pair with the lowest temperature.\n2. **Part 2:** Create a function to find the `station_id` with the most temperature fluctuation across all reported dates.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Backend/README.md", "chunk_number": 2, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "# Backend README\n\n## Overview\n\nThis coding exercise is designed to evaluate your Python programming skills, focusing on algorithm design and implementation. You have 2 hours to complete the tasks.\n\n## Tasks\n\n### Part 1\n\nWrite a function to find the `station_id` and `date` pair with the lowest recorded temperature.\n\n### Part 2\n\nWrite a function to find the `station_id` with the most temperature fluctuation across all reported dates.\n\n### Bonus Task\n\nDevelop a function that identifies the `station_id` with the most significant temperature fluctuation between a given date range.\n\n## Evaluation Criteria\n\n* Correctness\n* Readability\n* Coherent design\n* Test coverage\n\n## Guidelines\n\n* Minimize third-party library usage\n* Showcase your personal algorithms and design skills"}
{"code": "             1, 2000.456,             5\n\nwe are expecting the total fluctuation to be 10 degrees, as opposed to 0 which is the net difference\nin temperature between the first and last dates.\n\n**Part 3**:\n\nCreate a function that will return the `station_id` that experienced the most amount of temperature\nfluctuation for any given range of dates. I.e to get the result of 10 degrees from part 2 above, we\nwould expect the input dates to be `2000.001` and `2000.456`.\n\n## Evaluation Criteria\nWe will be evaluating your submission based on the following criteria, in no particular order:\n\n* Readability: Consistent styling, aptly named functions, and variables.\n* Coherent Design: Where applicable, sensisble abstractions are employed, functions are well intentioned.\n* Test coverage: The solution is tested, and proveably functions correctly.\n* Correctness\n\nIn other words, the end product should be something that you wouldn't hesitate to hit shippit on and\nproductionize!\n", "explanation": "**Summary**\n\nThe text describes a problem requiring the development of a function that identifies the `station_id` with the most significant temperature fluctuation between a given date range. The function should receive two dates as input and return the corresponding `station_id`. The solution will be evaluated based on readability, coherent design, test coverage, and correctness.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Backend/README.md", "chunk_number": 3, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "# Backend README\n\n## Overview\n\nThis coding exercise is designed to evaluate your Python programming skills, focusing on algorithm design and implementation. You have 2 hours to complete the tasks.\n\n## Tasks\n\n### Part 1\n\nWrite a function to find the `station_id` and `date` pair with the lowest recorded temperature.\n\n### Part 2\n\nWrite a function to find the `station_id` with the most temperature fluctuation across all reported dates.\n\n### Bonus Task\n\nDevelop a function that identifies the `station_id` with the most significant temperature fluctuation between a given date range.\n\n## Evaluation Criteria\n\n* Correctness\n* Readability\n* Coherent design\n* Test coverage\n\n## Guidelines\n\n* Minimize third-party library usage\n* Showcase your personal algorithms and design skills"}
{"code": "# This file is maintained automatically by \"terraform init\".\n# Manual edits may be lost in future updates.\n\nprovider \"registry.terraform.io/hashicorp/kubernetes\" {\n  version     = \"2.11.0\"\n  constraints = \"~> 2.11\"\n  hashes = [\n    \"h1:T65SZhN/tQgsAsHe/G5PCgpjofi+aTKPZ+nZg6WOJpc=\",\n    \"zh:143a19dd0ea3b07fc5e3d9231f3c2d01f92894385c98a67327de74c76c715843\",\n    \"zh:1fc757d209e09c3cf7848e4274daa32408c07743698fbed10ee52a4a479b62b6\",\n    \"zh:22dfebd0685749c51a8f765d51a1090a259778960ac1cd4f32021a325b2b9b72\",\n    \"zh:3039b3b76e870cd8fc404cf75a29c66b171c6ba9b6182e131b6ae2ca648ec7c0\",\n    \"zh:3af0a15562fcab4b5684b18802e0239371b2b8ff9197ed069ff4827f795a002b\",\n    \"zh:50aaf20336d1296a73315adb66f7687f75bd5c6b1f93a894b95c75cc142810ec\",\n    \"zh:682064fabff895ec351860b4fe0321290bbbb17c2a410b62c9bea0039400650e\",\n    \"zh:70ac914d5830b3371a2679d8f77cc20c419a6e12925145afae6c977c8eb90934\",\n    \"zh:710aa02cccf7b0f3fb50880d6d2a7a8b8c9435248666616844ba71f74648cddc\",", "explanation": "This block configures the Kubernetes provider for Terraform, specifying version 2.11.0 and a list of hashes for integrity verification.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/.terraform.lock.hcl", "chunk_number": 1, "total_chunks": 2}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The file 'DevOps/.terraform.lock.hcl' is used by Terraform for dependency management and locking. It contains a JSON object with hashed values, which serves as a lock file for storing and referencing hashed strings. The specific block included in this file configures the Kubernetes provider, version 2.11.0, with its corresponding integrity verification hashes for dependency locking. This ensures reproducibility and consistency in Terraform deployments."}
{"code": "    \"zh:88e418118cd5afbdec4984944c7ab36950bf48e8d3e09e090232e55eecfb470b\",\n    \"zh:9cef159377bf23fa331f8724fdc6ce27ad39a217a4bae6df3b1ca408fc643da6\",\n    \"zh:f569b65999264a9416862bca5cd2a6177d94ccb0424f3a4ef424428912b9cb3c\",\n  ]\n}\n", "explanation": "This block appears to be a JSON object containing an array of hash values with \"zh\" prefixes. The purpose is likely to store or reference a collection of unique, hashed strings in a programming context.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/.terraform.lock.hcl", "chunk_number": 2, "total_chunks": 2}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The file 'DevOps/.terraform.lock.hcl' is used by Terraform for dependency management and locking. It contains a JSON object with hashed values, which serves as a lock file for storing and referencing hashed strings. The specific block included in this file configures the Kubernetes provider, version 2.11.0, with its corresponding integrity verification hashes for dependency locking. This ensures reproducibility and consistency in Terraform deployments."}
{"code": "- [Overview](#overview)\n  - [Requirements](#requirements)\n- [Task](#task)\n  - [How to check](#how-to-check)\n- [Evaluation Criteria](#evaluation-criteria)\n\n# Overview\nUsually it's more comfortable to use Terraform modules than just \"long\" manifests. This repo contains `state-metrics` K8s service namespace and deployment manifest.\n\n## Requirements\n* Local K8s cluster >= v1.24\n\n# Task\n* Install `state-metrics` with given terraform manifests (you may need to update `config_path` in the `_provider.tf` file)\n  ```\n  terraform init\n  terraform apply\n  ```\n* Modify code to make `state-metrics` to be presented as module.\n* Migrate currently deployed service from \"plain manifest\" to terraform module.\n  * No pod should be recreated during the migration\n  * Module should have some input variables to customize created resources\n* Provide module and all related migration commands in the solution\n\n## How to check\nIn order to check if `state-metrics` is working just follow these steps:\n\n1. Get `state-metrics` pod ip with\n  ```sh", "explanation": "This block outlines the requirements and tasks for migrating a Kubernetes (K8s) deployment of `state-metrics` from a plain manifest to a Terraform module. The task involves:\n\n- Installing `state-metrics` using provided Terraform manifests\n- Modifying the code to present `state-metrics` as a reusable Terraform module\n- Migrating the existing deployment to the new Terraform module without recreating any pods\n- Providing a solution that includes the module and migration commands.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/README.md", "chunk_number": 1, "total_chunks": 2}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The `DevOps/README.md` file appears to provide instructions and guidelines for two primary tasks related to a Kubernetes (K8s) deployment of `state-metrics`:\n\n1. **Migrating `state-metrics` to a Terraform Module**: The file outlines tasks and requirements to migrate the existing `state-metrics` deployment from a plain manifest to a reusable Terraform module. This involves installing and modifying the code, as well as providing a smooth migration solution without recreating pods.\n\n2. **Testing the State Metrics Service**: The file includes a set of instructions to test the functionality and responsiveness of the state metrics service in a K8s cluster. The tasks involve verifying pod states and using `curl` to query the service and retrieve metrics data.\n\nAdditionally, the file includes evaluation criteria for submissions, focusing on code readability and correctness."}
{"code": "  kubectl get pods -o wide --all-namespaces | grep state\n  ```\n2. Run some container with `curl` installed inside K8s with shell. For example:\n  ```sh\n  kubectl run some-cli --rm -i -t   --image curlimages/curl  --overrides='{\"kind\":\"Pod\", \"apiVersion\":\"v1\", \"spec\": {\"hostNetwork\": true}}'   -- sh\n  ```\n3. Run\n  ```sh\n  curl ${STATE_METRICS_POD_IP}:18081/metrics\n  ```\n\n# Evaluation Criteria\nWe will be evaluating your submission based on the following criteria, in no particular order:\n* Readability: Consistent styling, aptly named functions, and variables.\n* Correctness: In other words, the end product should be something that you wouldn't hesitate to hit shippit on and productionize!\n", "explanation": "This block appears to be a set of instructions for testing the state metrics service in a Kubernetes (K8s) cluster.\n\n**Purpose:** The purpose is to verify the state metrics service is functional and responsive.\n\n**Functionality:**\n\n1. Retrieve a list of pods in all namespaces with extra information (`-o wide`) and filter the output to show pods with a specific state (`grep state`).\n2. Run a temporary container (`--rm`) with `curl` installed and execute a command interactively (`-i -t`) inside the K8s cluster with shell access (`sh`).\n3. Use `curl` to query the state metrics service at a specific IP address and port (`18081`) and retrieve metrics data.\n\nThe instructions also include evaluation criteria for a submission or assignment, focusing on readability and correctness.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/README.md", "chunk_number": 2, "total_chunks": 2}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The `DevOps/README.md` file appears to provide instructions and guidelines for two primary tasks related to a Kubernetes (K8s) deployment of `state-metrics`:\n\n1. **Migrating `state-metrics` to a Terraform Module**: The file outlines tasks and requirements to migrate the existing `state-metrics` deployment from a plain manifest to a reusable Terraform module. This involves installing and modifying the code, as well as providing a smooth migration solution without recreating pods.\n\n2. **Testing the State Metrics Service**: The file includes a set of instructions to test the functionality and responsiveness of the state metrics service in a K8s cluster. The tasks involve verifying pod states and using `curl` to query the service and retrieve metrics data.\n\nAdditionally, the file includes evaluation criteria for submissions, focusing on code readability and correctness."}
{"code": "provider \"kubernetes\" {\n  alias       = \"local\"\n  config_path = pathexpand(\"~/.kube/config\")\n}\n", "explanation": "**Kubernetes Provider Block**\n\nThis block sets up a Terraform provider for Kubernetes, aliasing it as \"local\". It specifies the configuration file path to the local Kubernetes cluster's `~/.kube/config` file, allowing Terraform to manage resources on the local cluster.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/_provider.tf", "chunk_number": 1, "total_chunks": 1}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The file 'DevOps/_provider.tf' is a Terraform configuration file that sets up a Kubernetes provider, enabling Terraform to manage resources on a local Kubernetes cluster by referencing the cluster's configuration file at '~/.kube/config'."}
{"code": "resource \"kubernetes_namespace\" \"mon_local\" {\n  provider = kubernetes.local\n\n  metadata {\n    name = \"mon\"\n  }\n}\n", "explanation": "**Summary**\n\nThis Terraform configuration block creates a Kubernetes namespace named \"mon\" using the `kubernetes.local` provider.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/namespace.tf", "chunk_number": 1, "total_chunks": 1}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "The 'DevOps/namespace.tf' file contains a Terraform configuration that creates a Kubernetes namespace named \"mon\" using the `kubernetes.local` provider."}
{"code": "/*\n  NOTE: Using `kubernetes_manifest` resource due to a bug in the terraform provider. Details can be found here:\n  https://github.com/hashicorp/terraform-provider-kubernetes/issues/1724#issuecomment-1139450178\n*/\nresource \"kubernetes_manifest\" \"state_metrics_local_sa\" {\n  provider = kubernetes.local\n\n  manifest = {\n    apiVersion = \"v1\"\n    kind       = \"ServiceAccount\"\n    metadata = {\n      namespace = kubernetes_namespace.mon_local.metadata[0].name\n      name      = \"state-metrics\"\n\n      labels = {\n        app = \"state-metrics\"\n      }\n    }\n\n    automountServiceAccountToken = false\n  }\n}\n\nresource \"kubernetes_secret\" \"state_metrics_local_sa_token\" {\n  provider = kubernetes.local\n\n  metadata {\n    name      = \"state-metrics-token\"\n    namespace = kubernetes_namespace.mon_local.metadata[0].name\n    annotations = {\n      \"kubernetes.io/service-account.name\" = kubernetes_manifest.state_metrics_local_sa.manifest.metadata.name\n    }\n  }\n\n  type = \"kubernetes.io/service-account-token\"\n}\n", "explanation": "**Functionality Summary**\n\nThis block of code creates a Kubernetes Service Account (`state-metrics`) and a corresponding Secret token, but with the service account token auto-mounting disabled. It uses a workaround (`kubernetes_manifest`) due to a Terraform provider bug.\n\n**Key Components:**\n\n1. Creates a Service Account (`state-metrics`) with disabled token auto-mounting.\n2. Creates a Secret token (`state-metrics-token`) for the Service Account.\n\n**Context:**\n\nThis code is likely used for monitoring applications in a Kubernetes cluster.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 1, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "resource \"kubernetes_cluster_role\" \"state_metrics_local\" {\n  provider = kubernetes.local\n\n  metadata {\n    name = \"state-metrics\"\n\n    labels = {\n      app = \"state-metrics\"\n    }\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"\"]\n    resources = [\n      \"configmaps\",\n      \"secrets\",\n      \"nodes\",\n      \"pods\",\n      \"services\",\n      \"resourcequotas\",\n      \"replicationcontrollers\",\n      \"limitranges\",\n      \"persistentvolumeclaims\",\n      \"persistentvolumes\",\n      \"namespaces\",\n      \"endpoints\"\n    ]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"extensions\"]\n    resources  = [\"daemonsets\", \"deployments\", \"replicasets\", \"ingresses\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"apps\"]\n    resources  = [\"statefulsets\", \"daemonsets\", \"deployments\", \"replicasets\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"batch\"]\n    resources  = [\"cronjobs\", \"jobs\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"autoscaling\"]", "explanation": "This Kubernetes Terraform resource creates a cluster role named \"state-metrics\" with permissions to list and watch various Kubernetes resources across different API groups.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 2, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "    resources  = [\"horizontalpodautoscalers\"]\n  }\n\n  rule {\n    verbs      = [\"create\"]\n    api_groups = [\"authentication.k8s.io\"]\n    resources  = [\"tokenreviews\"]\n  }\n\n  rule {\n    verbs      = [\"create\"]\n    api_groups = [\"authorization.k8s.io\"]\n    resources  = [\"subjectaccessreviews\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"policy\"]\n    resources  = [\"poddisruptionbudgets\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"certificates.k8s.io\"]\n    resources  = [\"certificatesigningrequests\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"storage.k8s.io\"]\n    resources  = [\"storageclasses\", \"volumeattachments\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"admissionregistration.k8s.io\"]\n    resources  = [\"mutatingwebhookconfigurations\", \"validatingwebhookconfigurations\"]\n  }\n\n  rule {\n    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"networking.k8s.io\"]\n    resources  = [\"networkpolicies\", \"ingresses\"]\n  }\n\n  rule {", "explanation": "**Summary:**\n\nThis block defines a set of Kubernetes role-based access control (RBAC) rules specifying API actions (verbs) that can be performed on various resources across different API groups.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 3, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "    verbs      = [\"list\", \"watch\"]\n    api_groups = [\"coordination.k8s.io\"]\n    resources  = [\"leases\"]\n  }\n}\n\nresource \"kubernetes_cluster_role_binding\" \"state_metrics_local\" {\n  provider = kubernetes.local\n\n  metadata {\n    name = \"state-metrics-binding\"\n\n    labels = {\n      app = \"state-metrics\"\n    }\n  }\n\n  role_ref {\n    kind      = \"ClusterRole\"\n    name      = kubernetes_cluster_role.state_metrics_local.metadata[0].name\n    api_group = \"rbac.authorization.k8s.io\"\n  }\n\n  subject {\n    kind      = \"ServiceAccount\"\n    name      = kubernetes_manifest.state_metrics_local_sa.manifest.metadata.name\n    namespace = kubernetes_namespace.mon_local.metadata[0].name\n    api_group = \"\"\n  }\n}\n\nresource \"kubernetes_deployment\" \"state_metrics_local\" {\n  provider = kubernetes.local\n\n  metadata {\n    name      = \"state-metrics\"\n    namespace = kubernetes_namespace.mon_local.metadata[0].name\n\n    labels = {\n      app = \"state-metrics\"\n    }\n  }\n\n  spec {\n    replicas = 1\n\n    strategy {\n      type = \"Recreate\"\n    }\n\n    selector {", "explanation": "This block defines three Kubernetes resources:\n\n1. **Cluster Role Binding**: Grants a service account access to cluster-level resources, specifically related to state metrics.\n2. **Deployment**: Creates a single replica of a containerized application (state metrics) in the \"mon_local\" namespace.\n3. **Implicitly referenced resources**: Cluster Role, Service Account, and Namespace are referenced but not defined in this block, suggesting they are created elsewhere in the code.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 4, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "      match_labels = {\n        app = \"state-metrics\"\n      }\n    }\n\n    progress_deadline_seconds = 180\n\n    template {\n      metadata {\n        namespace = kubernetes_namespace.mon_local.metadata[0].name\n        labels = {\n          app = \"state-metrics\"\n        }\n\n        annotations = {\n          # Full DD integradion doc:\n          # https://github.com/DataDog/integrations-core/blob/master/kubernetes_state/datadog_checks/kubernetes_state/data/conf.yaml.example\n          \"ad.datadoghq.com/state-metrics.check_names\"  = jsonencode([\"kubernetes_state\"])\n          \"ad.datadoghq.com/state-metrics.init_configs\" = \"[{}]\"\n          \"ad.datadoghq.com/state-metrics.instances\" = jsonencode([{\n            kube_state_url          = \"http://%%host%%:18080/metrics\"\n            prometheus_timeout      = 30\n            min_collection_interval = 30\n            telemetry               = true\n            label_joins = {\n              kube_deployment_labels = {\n                labels_to_match = [\"deployment\"]", "explanation": "This block configures a Kubernetes deployment for a Prometheus state-metrics exporter. It sets metadata, labels, and annotations for a Datadog integration, which monitors Kubernetes state and sends metrics to Datadog.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 5, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "                labels_to_get = [\n                  \"label_app\",\n                  \"label_deploy_env\",\n                  \"label_type\",\n                  \"label_magic_net\",\n                  \"label_canary\",\n                ]\n              }\n            }\n            labels_mapper = {\n              # We rename following labels because app and deploy_env are our \"well known labels\"\n              label_app        = \"app\"\n              label_deploy_env = \"deploy_env\"\n            }\n          }])\n        }\n      }\n\n      spec {\n        enable_service_links            = false\n        service_account_name            = kubernetes_manifest.state_metrics_local_sa.manifest.metadata.name\n        automount_service_account_token = true\n\n        host_network = true\n\n        container {\n          # docker run --rm -it k8s.gcr.io/kube-state-metrics/kube-state-metrics:v1.9.8 --help\n          image                    = \"k8s.gcr.io/kube-state-metrics/kube-state-metrics:v1.9.8\"\n          image_pull_policy        = \"IfNotPresent\"", "explanation": "This block defines a Kubernetes deployment specification for a `kube-state-metrics` container. It enables service accounts, disables service links, and specifies a Docker image. The container also uses the host network and maps labels for easier access.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 6, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "          name                     = \"state-metrics\"\n          termination_message_path = \"/dev/termination-log\"\n          command = [\n            \"/kube-state-metrics\",\n            \"--port=18080\",\n            \"--telemetry-port=18081\",\n          ]\n\n          readiness_probe {\n            http_get {\n              path = \"/healthz\"\n              port = \"18080\"\n            }\n\n            initial_delay_seconds = 5\n            timeout_seconds       = 5\n          }\n\n          resources {\n            requests = {\n              cpu    = \"30m\"\n              memory = \"30Mi\"\n            }\n\n            limits = {\n              cpu    = \"60m\"\n              memory = \"50Mi\"\n            }\n          }\n        }\n      }\n    }\n  }\n\n  depends_on = [\n    kubernetes_cluster_role_binding.state_metrics_local,\n  ]\n}\n", "explanation": "This block defines a Kubernetes pod configuration for `state-metrics`, a component that provides metrics about the state of the cluster. It specifies the command to run, port configurations, and resource requests/limits. The pod also includes a readiness probe to check the health of the service. Additionally, it has a dependency on a `state_metrics_local` Kubernetes cluster role binding.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/state-metrics.tf", "chunk_number": 7, "total_chunks": 7}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the 'DevOps/state-metrics.tf' file:\n\n**Overview**\n\nThis Terraform configuration sets up a Kubernetes deployment for state metrics, granting access to cluster resources and exporting metrics for monitoring.\n\n**Key Components**\n\n- Service Account (`state-metrics`): With disabled token auto-mounting and a corresponding secret token.\n- Cluster Role Binding: Grants access to cluster-level resources related to state metrics.\n- Deployment: Runs a Prometheus state-metrics exporter container in the `mon_local` namespace.\n- Pod Configuration: Specifies pod settings, including command, ports, resources, and readiness probe.\n- Kubernetes RBAC: Defines permissions for API actions on various resources across different API groups.\n\n**Purpose**\n\nThe primary purpose of this configuration is to monitor the state of a Kubernetes cluster and export metrics to a monitoring platform like Datadog."}
{"code": "terraform {\n  required_version = \">= 1.2.1\" # terraform\n  required_providers {\n    kubernetes = {\n      source  = \"hashicorp/kubernetes\"\n      version = \"~> 2.11\" # k8s\n    }\n  }\n}\n", "explanation": "This Terraform configuration block declares the required version of Terraform and a Kubernetes provider, specifying the version range for each.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "DevOps/versions.tf", "chunk_number": 1, "total_chunks": 1}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "Here's a concise summary of the `versions.tf` file in the `DevOps` directory:\n\nThe `versions.tf` file specifies the version requirements for Terraform and a Kubernetes provider, ensuring compatibility and stability in the deployment process."}
{"code": "## **Frontend Coding Challenge**\n\n### **General Guidelines:**\n\n- We value quality over quantity (feature-completeness). It is totally fine if things are left out as long as you make a note of it so we can see the trade-off and why you make the Decisions.\n\n- The project should be hosted on Github or any source control repository for review.\n- Commit history will help us to assess how you work during the challenge\n- A README should be included. Treat it like a service that you are pushing to production.ins and outs of the service should be discussed\n\n- Should focus on making the interfaces as polished as possible\n- Make sure it runs on multiple browsers and platforms\n\n### **Code Aspects:**\n\n- **Architecture**: Code layout and architecture for the given frameworks and libraries you use\n- **Technology**: What are some of the tradeoffs that you made to pick the technologies (frameworks, libraries, etc.) you used?", "explanation": "This block outlines the purpose and guidelines for a frontend coding challenge. The goal is to assess the participant's coding skills, decision-making, and commitment to quality. Key requirements include:\n\n- Creating a high-quality, polished interface\n- Hosting the project on a source control repository\n- Documenting trade-offs and decisions in the README and commit history\n- Ensuring cross-browser and platform compatibility", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Frontend/README.md", "chunk_number": 1, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "**Frontend/README.md Summary**\n\nThis file outlines the guidelines for a frontend coding challenge and a project called \"Film Locations in SF\". The challenge aims to assess coding skills, decision-making, and quality commitment by creating a high-quality, polished interface that is hosted on a source control repository, well-documented, and compatible across browsers and platforms. The project requires a user-friendly interface, maintainable code, thorough testing (utility function, integration, and rendering tests), and robust security measures. Additionally, the project utilizes data from the City of San Francisco's data portal and reminds developers to exclude public and secret keys and list any third-party services used."}
{"code": "- **Code Quality**: Is the code easy to read and maintainable? Consistent styling andbest practices for the languages used.\n- **UX**: Is the interface easy and intuitive to use?\n- **Testing**: Untested code is bad code. How are tests being set up? Is it easy to change if the service requirements are changed?\n- **Security**: What are some of the considerations that you've had to make sure the service is secure? Any obvious vulnerabilities?\n\n### **Project** :\n\nFilm Locations in SF\n\n- Description:\n  - Creates an app that shows where movies have been filmed on a map in SF. A trip planner that collects movie locations for the trip.\n\n- Minimum Requirements:\n  - It should be a client-side project. No backend server required.\n  - Users should be able to search for locations\n  - Create an itinerary\n  - Add movie location(s) to the trip\n  - Remove movie location(s)\n  - The user's trip planner should be persisted\n  - A map should be used to display the locations\n  - Implement one test case for each type below", "explanation": "**Summary**\n\nThis block outlines the requirements and considerations for a project called \"Film Locations in SF\", a client-side app that maps movie filming locations in San Francisco. The project requires a user-friendly interface, maintainable code, thorough testing, and robust security measures to ensure a secure and functional trip planner.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Frontend/README.md", "chunk_number": 2, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "**Frontend/README.md Summary**\n\nThis file outlines the guidelines for a frontend coding challenge and a project called \"Film Locations in SF\". The challenge aims to assess coding skills, decision-making, and quality commitment by creating a high-quality, polished interface that is hosted on a source control repository, well-documented, and compatible across browsers and platforms. The project requires a user-friendly interface, maintainable code, thorough testing (utility function, integration, and rendering tests), and robust security measures. Additionally, the project utilizes data from the City of San Francisco's data portal and reminds developers to exclude public and secret keys and list any third-party services used."}
{"code": "     - Utility function test\n     - Integration test\n     - Rendering test\n\n- Dataset:\n  - [https://data.sfgov.org/Culture-and-Recreation/Film-Locations-in-San-Francisco/yitu-d5am](https://data.sfgov.org/Culture-and-Recreation/Film-Locations-in-San-Francisco/yitu-d5am)\n  \n### Please DON'T include any public and secret keys in your project. Instead, please let us know the third-party services that you use if any\n", "explanation": "This appears to be a testing and data reference block, likely part of a coding project. \n\nThe block notes three types of tests: \n1. Utility function test\n2. Integration test\n3. Rendering test\n\nAdditionally, it references a dataset from the City of San Francisco's data portal, specifically film locations data.\n\nIt also reminds developers not to include public and secret keys in their project and instead to list any third-party services used.", "metadata": {"repo": "magiclabs/email_screening_question", "file": "Frontend/README.md", "chunk_number": 3, "total_chunks": 3}, "repository_explanation": "This repository contains a sample solution for Magic Labs' email screening question. \n\nThe purpose: \nProvide a code example for a specific problem statement that involves validating and processing a list of email addresses.\n\nThe content:\nThe repository likely includes source code in a programming language (e.g., Python), along with test cases, documentation, and possibly an explanation of the solution's design choices.", "file_summary": "**Frontend/README.md Summary**\n\nThis file outlines the guidelines for a frontend coding challenge and a project called \"Film Locations in SF\". The challenge aims to assess coding skills, decision-making, and quality commitment by creating a high-quality, polished interface that is hosted on a source control repository, well-documented, and compatible across browsers and platforms. The project requires a user-friendly interface, maintainable code, thorough testing (utility function, integration, and rendering tests), and robust security measures. Additionally, the project utilizes data from the City of San Francisco's data portal and reminds developers to exclude public and secret keys and list any third-party services used."}
